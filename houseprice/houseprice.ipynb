{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./data/train.csv\")\n",
    "test = pd.read_csv(\"./data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
      "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
      "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
      "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
      "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
      "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
      "1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
      "1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
      "1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
      "1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
      "1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
      "\n",
      "     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
      "0            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "1            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "2            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "3            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "4            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "...          ...       ...  ...      ...    ...    ...         ...     ...   \n",
      "1455         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "1456         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
      "1457         Lvl    AllPub  ...        0    NaN  GdPrv        Shed    2500   \n",
      "1458         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "1459         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "\n",
      "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
      "0         2   2008        WD         Normal     208500  \n",
      "1         5   2007        WD         Normal     181500  \n",
      "2         9   2008        WD         Normal     223500  \n",
      "3         2   2006        WD        Abnorml     140000  \n",
      "4        12   2008        WD         Normal     250000  \n",
      "...     ...    ...       ...            ...        ...  \n",
      "1455      8   2007        WD         Normal     175000  \n",
      "1456      2   2010        WD         Normal     210000  \n",
      "1457      5   2010        WD         Normal     266500  \n",
      "1458      4   2010        WD         Normal     142125  \n",
      "1459      6   2008        WD         Normal     147500  \n",
      "\n",
      "[1460 rows x 81 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "0     1461          20       RH         80.0    11622   Pave   NaN      Reg   \n",
      "1     1462          20       RL         81.0    14267   Pave   NaN      IR1   \n",
      "2     1463          60       RL         74.0    13830   Pave   NaN      IR1   \n",
      "3     1464          60       RL         78.0     9978   Pave   NaN      IR1   \n",
      "4     1465         120       RL         43.0     5005   Pave   NaN      IR1   \n",
      "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
      "1454  2915         160       RM         21.0     1936   Pave   NaN      Reg   \n",
      "1455  2916         160       RM         21.0     1894   Pave   NaN      Reg   \n",
      "1456  2917          20       RL        160.0    20000   Pave   NaN      Reg   \n",
      "1457  2918          85       RL         62.0    10441   Pave   NaN      Reg   \n",
      "1458  2919          60       RL         74.0     9627   Pave   NaN      Reg   \n",
      "\n",
      "     LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence  \\\n",
      "0            Lvl    AllPub  ...         120        0    NaN  MnPrv   \n",
      "1            Lvl    AllPub  ...           0        0    NaN    NaN   \n",
      "2            Lvl    AllPub  ...           0        0    NaN  MnPrv   \n",
      "3            Lvl    AllPub  ...           0        0    NaN    NaN   \n",
      "4            HLS    AllPub  ...         144        0    NaN    NaN   \n",
      "...          ...       ...  ...         ...      ...    ...    ...   \n",
      "1454         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
      "1455         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
      "1456         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
      "1457         Lvl    AllPub  ...           0        0    NaN  MnPrv   \n",
      "1458         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
      "\n",
      "     MiscFeature MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
      "0            NaN       0      6    2010        WD         Normal  \n",
      "1           Gar2   12500      6    2010        WD         Normal  \n",
      "2            NaN       0      3    2010        WD         Normal  \n",
      "3            NaN       0      6    2010        WD         Normal  \n",
      "4            NaN       0      1    2010        WD         Normal  \n",
      "...          ...     ...    ...     ...       ...            ...  \n",
      "1454         NaN       0      6    2006        WD         Normal  \n",
      "1455         NaN       0      4    2006        WD        Abnorml  \n",
      "1456         NaN       0      9    2006        WD        Abnorml  \n",
      "1457        Shed     700      7    2006        WD         Normal  \n",
      "1458         NaN       0     11    2006        WD         Normal  \n",
      "\n",
      "[1459 rows x 80 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat是将数据框连接在一起，默认是将第二个数据框连在第一个的下方，即按行方向连接，如果想要按列方向连接，需要设置axis=1\n",
    "features = pd.concat((train.drop(columns=['Id', 'SalePrice']), test.drop(columns=['Id'])))\n",
    "# 这里用到了布尔索引，其实布尔索引就是一串布尔数组，True就取，False就不取，features.dtypes返回序列，所以利用不等式能创建布尔索引\n",
    "numeric_features = features.dtypes[features.dtypes != 'object'].index\n",
    "# apply是对列表中的每个元素都应用括号里的函数，比如a = [1, 2, 3]，a.apply(lambda x: x + 1)得到的是[2, 3, 4]\n",
    "features[numeric_features] = features[numeric_features].apply(lambda x: (x - x.mean()) / x.std())\n",
    "features[numeric_features] = features[numeric_features].fillna(0)\n",
    "# 自动进行独热编码，对于nan值也要单独生成一列\n",
    "features = pd.get_dummies(features, dummy_na=True)\n",
    "\n",
    "train_features = features[:len(train)].copy()\n",
    "test_features = features[len(train):].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      MSSubClass  LotFrontage   LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
      "0       0.067320    -0.184443 -0.217841     0.646073    -0.507197   1.046078   \n",
      "1      -0.873466     0.458096 -0.072032    -0.063174     2.187904   0.154737   \n",
      "2       0.067320    -0.055935  0.137173     0.646073    -0.507197   0.980053   \n",
      "3       0.302516    -0.398622 -0.078371     0.646073    -0.507197  -1.859033   \n",
      "4       0.067320     0.629439  0.518814     1.355319    -0.507197   0.947040   \n",
      "...          ...          ...       ...          ...          ...        ...   \n",
      "1455    0.067320    -0.312950 -0.285421    -0.063174    -0.507197   0.914028   \n",
      "1456   -0.873466     0.672275  0.381246    -0.063174     0.391170   0.220763   \n",
      "1457    0.302516    -0.141607 -0.142781     0.646073     3.086271  -1.000704   \n",
      "1458   -0.873466    -0.055935 -0.057197    -0.772420     0.391170  -0.703591   \n",
      "1459   -0.873466     0.243916 -0.029303    -0.772420     0.391170  -0.208401   \n",
      "\n",
      "      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  SaleType_Oth  \\\n",
      "0         0.896679    0.523038    0.580708   -0.293030  ...         False   \n",
      "1        -0.395536   -0.569893    1.177709   -0.293030  ...         False   \n",
      "2         0.848819    0.333448    0.097840   -0.293030  ...         False   \n",
      "3        -0.682695   -0.569893   -0.494771   -0.293030  ...         False   \n",
      "4         0.753100    1.381770    0.468770   -0.293030  ...         False   \n",
      "...            ...         ...         ...         ...  ...           ...   \n",
      "1455      0.753100   -0.569893   -0.968860   -0.293030  ...         False   \n",
      "1456      0.178782    0.093673    0.765076    0.670295  ...         False   \n",
      "1457      1.040259   -0.569893   -0.365275   -0.293030  ...         False   \n",
      "1458      0.561660   -0.569893   -0.861312    5.788329  ...         False   \n",
      "1459     -0.921995   -0.569893    0.852870    1.420862  ...         False   \n",
      "\n",
      "      SaleType_WD  SaleType_nan  SaleCondition_Abnorml  SaleCondition_AdjLand  \\\n",
      "0            True         False                  False                  False   \n",
      "1            True         False                  False                  False   \n",
      "2            True         False                  False                  False   \n",
      "3            True         False                   True                  False   \n",
      "4            True         False                  False                  False   \n",
      "...           ...           ...                    ...                    ...   \n",
      "1455         True         False                  False                  False   \n",
      "1456         True         False                  False                  False   \n",
      "1457         True         False                  False                  False   \n",
      "1458         True         False                  False                  False   \n",
      "1459         True         False                  False                  False   \n",
      "\n",
      "      SaleCondition_Alloca  SaleCondition_Family  SaleCondition_Normal  \\\n",
      "0                    False                 False                  True   \n",
      "1                    False                 False                  True   \n",
      "2                    False                 False                  True   \n",
      "3                    False                 False                 False   \n",
      "4                    False                 False                  True   \n",
      "...                    ...                   ...                   ...   \n",
      "1455                 False                 False                  True   \n",
      "1456                 False                 False                  True   \n",
      "1457                 False                 False                  True   \n",
      "1458                 False                 False                  True   \n",
      "1459                 False                 False                  True   \n",
      "\n",
      "      SaleCondition_Partial  SaleCondition_nan  \n",
      "0                     False              False  \n",
      "1                     False              False  \n",
      "2                     False              False  \n",
      "3                     False              False  \n",
      "4                     False              False  \n",
      "...                     ...                ...  \n",
      "1455                  False              False  \n",
      "1456                  False              False  \n",
      "1457                  False              False  \n",
      "1458                  False              False  \n",
      "1459                  False              False  \n",
      "\n",
      "[1460 rows x 330 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      MSSubClass  LotFrontage   LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
      "0      -0.873466     0.458096  0.184340    -0.772420     0.391170  -0.340452   \n",
      "1      -0.873466     0.500932  0.519702    -0.063174     0.391170  -0.439490   \n",
      "2       0.067320     0.201080  0.464294    -0.772420    -0.507197   0.848003   \n",
      "3       0.067320     0.372424 -0.024105    -0.063174     0.391170   0.881015   \n",
      "4       1.478499    -1.126832 -0.654636     1.355319    -0.507197   0.682939   \n",
      "...          ...          ...       ...          ...          ...        ...   \n",
      "1454    2.419286    -2.069222 -1.043758    -1.481667     1.289537  -0.043338   \n",
      "1455    2.419286    -2.069222 -1.049083    -1.481667    -0.507197  -0.043338   \n",
      "1456   -0.873466     3.884968  1.246594    -0.772420     1.289537  -0.373465   \n",
      "1457    0.655311    -0.312950  0.034599    -0.772420    -0.507197   0.682939   \n",
      "1458    0.067320     0.201080 -0.068608     0.646073    -0.507197   0.715952   \n",
      "\n",
      "      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  SaleType_Oth  \\\n",
      "0        -1.113434   -0.569893    0.058332    0.558006  ...         False   \n",
      "1        -1.257014    0.032335    1.056991   -0.293030  ...         False   \n",
      "2         0.657380   -0.569893    0.767271   -0.293030  ...         False   \n",
      "3         0.657380   -0.458369    0.352443   -0.293030  ...         False   \n",
      "4         0.370221   -0.569893   -0.391613   -0.293030  ...         False   \n",
      "...            ...         ...         ...         ...  ...           ...   \n",
      "1454     -0.682695   -0.569893   -0.968860   -0.293030  ...         False   \n",
      "1455     -0.682695   -0.569893   -0.415757   -0.293030  ...         False   \n",
      "1456      0.561660   -0.569893    1.717643   -0.293030  ...         False   \n",
      "1457      0.370221   -0.569893   -0.229194   -0.293030  ...         False   \n",
      "1458      0.465941   -0.045732    0.694840   -0.293030  ...         False   \n",
      "\n",
      "      SaleType_WD  SaleType_nan  SaleCondition_Abnorml  SaleCondition_AdjLand  \\\n",
      "0            True         False                  False                  False   \n",
      "1            True         False                  False                  False   \n",
      "2            True         False                  False                  False   \n",
      "3            True         False                  False                  False   \n",
      "4            True         False                  False                  False   \n",
      "...           ...           ...                    ...                    ...   \n",
      "1454         True         False                  False                  False   \n",
      "1455         True         False                   True                  False   \n",
      "1456         True         False                   True                  False   \n",
      "1457         True         False                  False                  False   \n",
      "1458         True         False                  False                  False   \n",
      "\n",
      "      SaleCondition_Alloca  SaleCondition_Family  SaleCondition_Normal  \\\n",
      "0                    False                 False                  True   \n",
      "1                    False                 False                  True   \n",
      "2                    False                 False                  True   \n",
      "3                    False                 False                  True   \n",
      "4                    False                 False                  True   \n",
      "...                    ...                   ...                   ...   \n",
      "1454                 False                 False                  True   \n",
      "1455                 False                 False                 False   \n",
      "1456                 False                 False                 False   \n",
      "1457                 False                 False                  True   \n",
      "1458                 False                 False                  True   \n",
      "\n",
      "      SaleCondition_Partial  SaleCondition_nan  \n",
      "0                     False              False  \n",
      "1                     False              False  \n",
      "2                     False              False  \n",
      "3                     False              False  \n",
      "4                     False              False  \n",
      "...                     ...                ...  \n",
      "1454                  False              False  \n",
      "1455                  False              False  \n",
      "1456                  False              False  \n",
      "1457                  False              False  \n",
      "1458                  False              False  \n",
      "\n",
      "[1459 rows x 330 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(180921.1875) tensor(79442.5000)\n"
     ]
    }
   ],
   "source": [
    "label = pd.DataFrame(train['SalePrice'])\n",
    "labeldata = torch.tensor(label.values.astype(float), dtype=torch.float32)\n",
    "labelmean = labeldata.mean()\n",
    "labelstd = labeldata.std()\n",
    "labeldata = (labeldata -labelmean) / labelstd\n",
    "print(labelmean, labelstd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:1'\n",
    "batch_size = 1\n",
    "epoches = 100\n",
    "k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriceTrainSet(Dataset):\n",
    "    def __init__(self, device, inputs:pd.DataFrame, targets:torch.Tensor):\n",
    "        super(PriceTrainSet, self).__init__()\n",
    "        # 转换而来的ndarry是object型，需要astype手动转为float\n",
    "        self.x = torch.tensor(inputs.values.astype(float), dtype=torch.float32).to(device)\n",
    "        self.y = targets.clone().to(device)\n",
    "        # print(self.x.shape, self.y.shape)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriceTestSet(Dataset):\n",
    "    def __init__(self, device, inputs:pd.DataFrame):\n",
    "        super(PriceTestSet, self).__init__()\n",
    "        self.x = torch.tensor(inputs.values.astype(float), dtype=torch.float32).to(device)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindatas = []\n",
    "trainlabel = []\n",
    "blocksize = len(train_features) // k\n",
    "for i in range(k):\n",
    "    traindatas.append(train_features[i * blocksize:(i + 1) * blocksize])\n",
    "    trainlabel.append(labeldata[i * blocksize:(i + 1) * blocksize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = PriceTestSet(device, test_features)\n",
    "testloader = DataLoader(testset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, inputs, outputs, hiddens, layers, dropout=0.1):\n",
    "        super(Model, self).__init__()\n",
    "        self.net = nn.Sequential()\n",
    "        self.net.add_module(\n",
    "            'input', \n",
    "            nn.Sequential(\n",
    "                nn.Linear(inputs, hiddens), \n",
    "                nn.ReLU(), \n",
    "                nn.Dropout(dropout)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        for _ in range(layers - 2):\n",
    "            self.net.add_module(\n",
    "                'layer' + str(_ + 1), \n",
    "                nn.Sequential(\n",
    "                    nn.Linear(hiddens, hiddens), \n",
    "                    nn.ReLU(), \n",
    "                    nn.Dropout(dropout)\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        self.net.add_module('output', nn.Linear(hiddens, outputs))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log:\n",
    "    def __init__(self, filename):\n",
    "        self.file = open(filename, 'w')\n",
    "    \n",
    "    def log(self, text):\n",
    "        self.file.write(text)\n",
    "        self.file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, optimizer, criterion, log=None):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.log = log\n",
    "\n",
    "    def train(self, num_epoch, trainloader, testloader, logargs=None):\n",
    "        for i in range(num_epoch):\n",
    "            loss = self.train_epoch(trainloader)\n",
    "            print(f'train {i} epoch, loss: {loss}')\n",
    "        if testloader is not None:\n",
    "            testloss = self.test(testloader)\n",
    "            print(f'test loss: {testloss}')\n",
    "            if self.log is not None:\n",
    "                self.log.log(logargs + ':' + str(testloss))\n",
    "\n",
    "    def train_epoch(self, dataloader):\n",
    "        total_loss = 0.0\n",
    "        for x, y in dataloader:\n",
    "            total_loss += self.train_step(x, y)\n",
    "        return total_loss / len(dataloader)\n",
    "\n",
    "    def train_step(self, inputs, targets):\n",
    "        self.model.train()\n",
    "        outputs = self.model(inputs)\n",
    "        # print(outputs.shape, targets.shape)\n",
    "        loss = self.criterion(outputs, targets)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        #print(outputs, targets)\n",
    "        return loss.item()\n",
    "    \n",
    "    def test(self, dataloader):\n",
    "        total_loss = 0.0\n",
    "        for x, y in dataloader:\n",
    "            total_loss += self.test_step(x, y)\n",
    "        return total_loss / len(dataloader)\n",
    "    \n",
    "    def test_step(self, inputs, targets):\n",
    "        self.model.eval()\n",
    "        outputs = self.model(inputs)\n",
    "        loss = self.criterion(outputs, targets)\n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers = [512, 1024, 2048]\n",
    "lrs = [0.001]\n",
    "layers = [3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "log = Log('log.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training hidden_layers:512, layers:[3, 4, 5], lr:0.001\n",
      "train 0 epoch, loss: 0.43110285147711885\n",
      "train 1 epoch, loss: 0.20739736834250275\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m trainloader \u001b[39m=\u001b[39m DataLoader(trainset, batch_size\u001b[39m=\u001b[39mbatch_size)\n\u001b[1;32m     19\u001b[0m valloader \u001b[39m=\u001b[39m DataLoader(valset, batch_size\u001b[39m=\u001b[39mbatch_size)\n\u001b[0;32m---> 21\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain(epoches, trainloader, valloader, \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mhidden \u001b[39;49m\u001b[39m{\u001b[39;49;00mhidden\u001b[39m}\u001b[39;49;00m\u001b[39m, layer \u001b[39;49m\u001b[39m{\u001b[39;49;00mlayer\u001b[39m}\u001b[39;49;00m\u001b[39m, lr \u001b[39;49m\u001b[39m{\u001b[39;49;00mlr\u001b[39m}\u001b[39;49;00m\u001b[39m \u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     22\u001b[0m i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[17], line 10\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, num_epoch, trainloader, testloader, logargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m, num_epoch, trainloader, testloader, logargs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m      9\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epoch):\n\u001b[0;32m---> 10\u001b[0m         loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_epoch(trainloader)\n\u001b[1;32m     11\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m epoch, loss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m     \u001b[39mif\u001b[39;00m testloader \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[17], line 21\u001b[0m, in \u001b[0;36mTrainer.train_epoch\u001b[0;34m(self, dataloader)\u001b[0m\n\u001b[1;32m     19\u001b[0m total_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m dataloader:\n\u001b[0;32m---> 21\u001b[0m     total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step(x, y)\n\u001b[1;32m     22\u001b[0m \u001b[39mreturn\u001b[39;00m total_loss \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(dataloader)\n",
      "Cell \u001b[0;32mIn[17], line 31\u001b[0m, in \u001b[0;36mTrainer.train_step\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     30\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 31\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     32\u001b[0m \u001b[39m#print(outputs, targets)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39mreturn\u001b[39;00m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.9/site-packages/torch/optim/optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.9/site-packages/torch/optim/sgd.py:146\u001b[0m, in \u001b[0;36mSGD.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m             momentum_buffer_list\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mmomentum_buffer\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 146\u001b[0m sgd(params_with_grad,\n\u001b[1;32m    147\u001b[0m     d_p_list,\n\u001b[1;32m    148\u001b[0m     momentum_buffer_list,\n\u001b[1;32m    149\u001b[0m     weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    150\u001b[0m     momentum\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmomentum\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    151\u001b[0m     lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    152\u001b[0m     dampening\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdampening\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    153\u001b[0m     nesterov\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mnesterov\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    154\u001b[0m     maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    155\u001b[0m     has_sparse_grad\u001b[39m=\u001b[39;49mhas_sparse_grad,\n\u001b[1;32m    156\u001b[0m     foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    158\u001b[0m \u001b[39m# update momentum_buffers in state\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39mfor\u001b[39;00m p, momentum_buffer \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(params_with_grad, momentum_buffer_list):\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.9/site-packages/torch/optim/sgd.py:197\u001b[0m, in \u001b[0;36msgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, has_sparse_grad, foreach, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_sgd\n\u001b[0;32m--> 197\u001b[0m func(params,\n\u001b[1;32m    198\u001b[0m      d_p_list,\n\u001b[1;32m    199\u001b[0m      momentum_buffer_list,\n\u001b[1;32m    200\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    201\u001b[0m      momentum\u001b[39m=\u001b[39;49mmomentum,\n\u001b[1;32m    202\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    203\u001b[0m      dampening\u001b[39m=\u001b[39;49mdampening,\n\u001b[1;32m    204\u001b[0m      nesterov\u001b[39m=\u001b[39;49mnesterov,\n\u001b[1;32m    205\u001b[0m      has_sparse_grad\u001b[39m=\u001b[39;49mhas_sparse_grad,\n\u001b[1;32m    206\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize)\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.9/site-packages/torch/optim/sgd.py:241\u001b[0m, in \u001b[0;36m_single_tensor_sgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov, maximize, has_sparse_grad)\u001b[0m\n\u001b[1;32m    238\u001b[0m         d_p \u001b[39m=\u001b[39m buf\n\u001b[1;32m    240\u001b[0m alpha \u001b[39m=\u001b[39m lr \u001b[39mif\u001b[39;00m maximize \u001b[39melse\u001b[39;00m \u001b[39m-\u001b[39mlr\n\u001b[0;32m--> 241\u001b[0m param\u001b[39m.\u001b[39;49madd_(d_p, alpha\u001b[39m=\u001b[39;49malpha)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inputs = 330\n",
    "outputs = 1\n",
    "i = 0\n",
    "for hidden in hidden_layers:\n",
    "        for layer in layers:\n",
    "            for lr in lrs:\n",
    "                print(f'training hidden_layers:{hidden}, layers:{layers}, lr:{lr}')\n",
    "                model = Model(inputs, outputs, hidden, layer).to(device)\n",
    "                optimizer = torch.optim.SGD(model.parameters(), lr)\n",
    "                trainer = Trainer(model, optimizer, criterion, log)\n",
    "                \n",
    "                trainset = PriceTrainSet(\n",
    "                     device, \n",
    "                     pd.concat([traindatas[j] for j in range(k) if j != i]), \n",
    "                     torch.concat([trainlabel[j] for j in range(k) if j != i])\n",
    "                )\n",
    "                valset = PriceTrainSet(device, traindatas[i], trainlabel[i])\n",
    "                trainloader = DataLoader(trainset, batch_size=batch_size)\n",
    "                valloader = DataLoader(valset, batch_size=batch_size)\n",
    "\n",
    "                trainer.train(epoches, trainloader, valloader, f'hidden {hidden}, layer {layer}, lr {lr} ')\n",
    "                i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0 epoch, loss: 0.41652966200746516\n",
      "train 1 epoch, loss: 0.18197963772997783\n",
      "train 2 epoch, loss: 0.15816598282159552\n",
      "train 3 epoch, loss: 0.13899329997684856\n",
      "train 4 epoch, loss: 0.13052959575597803\n",
      "train 5 epoch, loss: 0.11095228148575922\n",
      "train 6 epoch, loss: 0.10040900867153454\n",
      "train 7 epoch, loss: 0.09772185669629355\n",
      "train 8 epoch, loss: 0.0819954177907814\n",
      "train 9 epoch, loss: 0.08070270076151485\n",
      "train 10 epoch, loss: 0.07446312772768537\n",
      "train 11 epoch, loss: 0.07293954647976514\n",
      "train 12 epoch, loss: 0.0701028553866953\n",
      "train 13 epoch, loss: 0.06294925551713829\n",
      "train 14 epoch, loss: 0.05090567452231701\n",
      "train 15 epoch, loss: 0.056723945541290045\n",
      "train 16 epoch, loss: 0.049949312264562576\n",
      "train 17 epoch, loss: 0.04631707196461671\n",
      "train 18 epoch, loss: 0.04718162522574634\n",
      "train 19 epoch, loss: 0.04447514331666519\n",
      "train 20 epoch, loss: 0.039323063952116585\n",
      "train 21 epoch, loss: 0.04057228676375422\n",
      "train 22 epoch, loss: 0.040443237532734495\n",
      "train 23 epoch, loss: 0.037809606851508894\n",
      "train 24 epoch, loss: 0.03721319317478861\n",
      "train 25 epoch, loss: 0.03555223363219006\n",
      "train 26 epoch, loss: 0.03439257208838248\n",
      "train 27 epoch, loss: 0.03472306685719219\n",
      "train 28 epoch, loss: 0.033319434667605084\n",
      "train 29 epoch, loss: 0.032364113805037016\n",
      "train 30 epoch, loss: 0.03458954546571496\n",
      "train 31 epoch, loss: 0.031248896896165536\n",
      "train 32 epoch, loss: 0.030635834706776013\n",
      "train 33 epoch, loss: 0.030536518244639564\n",
      "train 34 epoch, loss: 0.027279544761152318\n",
      "train 35 epoch, loss: 0.027884191357224322\n",
      "train 36 epoch, loss: 0.028813548153259365\n",
      "train 37 epoch, loss: 0.02781149062702501\n",
      "train 38 epoch, loss: 0.0269880726889671\n",
      "train 39 epoch, loss: 0.02664884773710247\n",
      "train 40 epoch, loss: 0.025222770233111307\n",
      "train 41 epoch, loss: 0.024540955832006255\n",
      "train 42 epoch, loss: 0.025175855464484417\n",
      "train 43 epoch, loss: 0.02407358514533406\n",
      "train 44 epoch, loss: 0.0237190299726541\n",
      "train 45 epoch, loss: 0.023278331570496785\n",
      "train 46 epoch, loss: 0.022627419934126366\n",
      "train 47 epoch, loss: 0.021230779382681968\n",
      "train 48 epoch, loss: 0.021296357257049696\n",
      "train 49 epoch, loss: 0.022003781104721534\n",
      "train 50 epoch, loss: 0.022950441761651123\n",
      "train 51 epoch, loss: 0.0221853037793208\n",
      "train 52 epoch, loss: 0.019629272829836918\n",
      "train 53 epoch, loss: 0.020219623311969442\n",
      "train 54 epoch, loss: 0.02142834680157945\n",
      "train 55 epoch, loss: 0.02110876023935222\n",
      "train 56 epoch, loss: 0.0210030803809642\n",
      "train 57 epoch, loss: 0.018743900061482303\n",
      "train 58 epoch, loss: 0.017906478047252584\n",
      "train 59 epoch, loss: 0.019445194480308087\n",
      "train 60 epoch, loss: 0.019111419966426905\n",
      "train 61 epoch, loss: 0.019599875506221002\n",
      "train 62 epoch, loss: 0.017926871476099383\n",
      "train 63 epoch, loss: 0.01830508921245041\n",
      "train 64 epoch, loss: 0.017755796182895463\n",
      "train 65 epoch, loss: 0.01633490913331314\n",
      "train 66 epoch, loss: 0.01842648469873623\n",
      "train 67 epoch, loss: 0.01632589152821419\n",
      "train 68 epoch, loss: 0.01857715016193105\n",
      "train 69 epoch, loss: 0.017032238630363124\n",
      "train 70 epoch, loss: 0.015437375720354363\n",
      "train 71 epoch, loss: 0.01720051409857497\n",
      "train 72 epoch, loss: 0.015831430832941112\n",
      "train 73 epoch, loss: 0.016267352449356176\n",
      "train 74 epoch, loss: 0.015656350151602983\n",
      "train 75 epoch, loss: 0.016067372919407085\n",
      "train 76 epoch, loss: 0.014271872422172122\n",
      "train 77 epoch, loss: 0.014430145268930383\n",
      "train 78 epoch, loss: 0.014731263095607086\n",
      "train 79 epoch, loss: 0.016128409014484053\n",
      "train 80 epoch, loss: 0.017750904921392908\n",
      "train 81 epoch, loss: 0.016024134945987117\n",
      "train 82 epoch, loss: 0.015659951993905196\n",
      "train 83 epoch, loss: 0.015844567836030235\n",
      "train 84 epoch, loss: 0.015638219601815377\n",
      "train 85 epoch, loss: 0.015224842212115921\n",
      "train 86 epoch, loss: 0.014616932558092467\n",
      "train 87 epoch, loss: 0.014724674059725653\n",
      "train 88 epoch, loss: 0.013732513289239778\n",
      "train 89 epoch, loss: 0.015012935985679876\n",
      "train 90 epoch, loss: 0.014246764148750991\n",
      "train 91 epoch, loss: 0.013994446903070463\n",
      "train 92 epoch, loss: 0.013438296902701694\n",
      "train 93 epoch, loss: 0.013945892306444125\n",
      "train 94 epoch, loss: 0.013761608748098656\n",
      "train 95 epoch, loss: 0.012859535450115348\n",
      "train 96 epoch, loss: 0.013782450698952071\n",
      "train 97 epoch, loss: 0.012517880998102913\n",
      "train 98 epoch, loss: 0.012580221465076705\n",
      "train 99 epoch, loss: 0.012247597237060186\n"
     ]
    }
   ],
   "source": [
    "inputs = 330\n",
    "outputs = 1\n",
    "hidden = 512\n",
    "model = Model(inputs, outputs, hidden, 3).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), 0.001)\n",
    "trainer = Trainer(model, optimizer, criterion)\n",
    "\n",
    "trainset = PriceTrainSet(device, train_features, labeldata)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size)\n",
    "\n",
    "trainer.train(epoches, trainloader, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = []\n",
    "y = []\n",
    "mean = labelmean.item()\n",
    "std = labelstd.item()\n",
    "for i in range(len(testset)):\n",
    "    id.append(i + 1461)    \n",
    "    y_hat = model(testset[i])\n",
    "    y.append(y_hat.item() * std + mean)\n",
    "df = pd.DataFrame(id, columns=['Id'])\n",
    "df['SalePrice'] = y\n",
    "df.to_csv('res.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
